% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/item_generation.R
\name{generate_items_via_llm}
\alias{generate_items_via_llm}
\title{Generate Items via LLM}
\usage{
generate_items_via_llm(
  main.prompts,
  system.role,
  model,
  top.p,
  temperature,
  adaptive,
  silently,
  groq.API,
  openai.API,
  anthropic.API = NULL,
  target.N
)
}
\arguments{
\item{main.prompts}{Named list of prompts for each item type}

\item{system.role}{Character string defining the system role}

\item{model}{Character string specifying the model}

\item{top.p}{Numeric. Nucleus sampling parameter}

\item{temperature}{Numeric. Sampling temperature}

\item{adaptive}{Logical. Use adaptive generation with previous items?}

\item{silently}{Logical. Suppress progress messages?}

\item{groq.API}{Optional Groq API key}

\item{openai.API}{Optional OpenAI API key}

\item{target.N}{Named list of target item counts per type}
}
\value{
A list with 'items' data frame and 'successful' flag
}
\description{
Generates scale items using the specified LLM provider. Supports OpenAI,
Groq, and local GGUF models.
}
\keyword{internal}
