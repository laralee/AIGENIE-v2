% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/generation_utils.R
\name{embed_items_huggingface}
\alias{embed_items_huggingface}
\title{Generate Embeddings Using Hugging Face Models}
\usage{
embed_items_huggingface(
  embedding.model = "BAAI/bge-base-en-v1.5",
  hf.token = NULL,
  items,
  silently = FALSE
)
}
\arguments{
\item{embedding.model}{Character string specifying the Hugging Face model to use.
Default is "BAAI/bge-base-en-v1.5". Compatible models include:
\itemize{
\item BAAI/bge series: "BAAI/bge-small-en-v1.5" (384 dims),
"BAAI/bge-base-en-v1.5" (768 dims), "BAAI/bge-large-en-v1.5" (1024 dims)
\item GTE series: "thenlper/gte-small" (384 dims), "thenlper/gte-base" (768 dims),
"thenlper/gte-large" (1024 dims)
}
Note: sentence-transformers models (e.g., all-MiniLM-L6-v2) are NOT compatible
as they are configured for sentence similarity, not feature extraction.}

\item{hf.token}{Optional character string. Hugging Face API token for increased rate
limits and access to private models. Public models work without a token, but may
have lower rate limits. Get a free token at https://huggingface.co/settings/tokens}

\item{items}{Data frame containing the items to embed. Must have two columns:
\itemize{
\item \code{statement}: Character vector of text to embed
\item \code{ID}: Unique identifiers for each statement
}}

\item{silently}{Logical. If FALSE (default), displays progress messages during
embedding generation. Set to TRUE to suppress all messages except errors.}
}
\value{
A list with two elements:
\itemize{
\item \code{embeddings}: Numeric matrix where each column represents one item's
embedding vector and each row represents an embedding dimension. Column
names correspond to the item IDs. Returns NULL if embedding fails.
\item \code{success}: Logical indicating whether embedding generation was
successful (TRUE) or failed (FALSE).
}
}
\description{
Generates dense vector embeddings for text items using open-source embedding models
hosted on Hugging Face's Inference API. This function provides a free alternative
to OpenAI's embedding models, with no API key required for public models.
}
\details{
The function connects to Hugging Face's Inference API to generate embeddings.
On first use of a model, there may be a 10-30 second delay while the model loads
on Hugging Face's servers. Subsequent requests will be faster.

The function automatically handles:
\itemize{
\item Model loading delays (503 responses)
\item Rate limiting (429 responses)
\item Retry logic with exponential backoff
}
}
\note{
\itemize{
\item Free tier rate limits: ~100-1000 requests per hour (varies by model)
\item With HF token: Higher rate limits and priority queue access
\item Embedding dimensions vary by model (384, 768, or 1024 typically)
\item Internet connection required
}
}
\examples{
\dontrun{
# Create sample items
items <- data.frame(
  statement = c("I enjoy social gatherings",
                "I prefer working alone"),
  ID = c("item_1", "item_2")
)

# Generate embeddings with default model (no API key needed)
result <- embed_items_huggingface(
  items = items,
  silently = FALSE
)

# Use a different model with HF token for better performance
result <- embed_items_huggingface(
  embedding.model = "BAAI/bge-large-en-v1.5",
  hf.token = "hf_xxxxx",
  items = items,
  silently = FALSE
)

# Check success and examine embeddings
if (result$success) {
  dim(result$embeddings)  # rows = embedding dims, cols = number of items
  colnames(result$embeddings)  # Should be item IDs
}
}

}
