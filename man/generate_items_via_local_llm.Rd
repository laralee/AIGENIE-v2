% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/local_item_generation.R
\name{generate_items_via_local_llm}
\alias{generate_items_via_local_llm}
\title{Generate Items Using Local LLM}
\usage{
generate_items_via_local_llm(
  main.prompts,
  system.role,
  model.path,
  temperature,
  top.p,
  adaptive,
  silently,
  target.N,
  n.ctx = 4096,
  n.gpu.layers = -1,
  max.tokens = 1024
)
}
\arguments{
\item{main.prompts}{Named list of prompts, one per item type}

\item{system.role}{Character string defining the system role}

\item{model.path}{Path to local GGUF model file}

\item{temperature}{Numeric between 0 and 2 for randomness}

\item{top.p}{Numeric between 0 and 1 for nucleus sampling}

\item{adaptive}{Logical. If TRUE, includes previous items to avoid repetition}

\item{silently}{Logical. If FALSE, displays progress}

\item{target.N}{Named list of target items per type}

\item{n.ctx}{Integer. Context window size (default 4096)}

\item{n.gpu.layers}{Integer. Number of layers to offload to GPU (-1 for all)}

\item{max.tokens}{Integer. Maximum tokens per generation (default 1024)}
}
\value{
A list containing items dataframe and success flag
}
\description{
Generates scale items using locally installed language models in GGUF format.
This provides a privacy-preserving alternative to API-based generation.
}
