% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/item_generation.R
\name{check_local_llm_setup}
\alias{check_local_llm_setup}
\title{Check Local LLM Setup}
\usage{
check_local_llm_setup(model.path, silently = FALSE)
}
\arguments{
\item{model.path}{Path to the GGUF model file}

\item{silently}{Logical. Suppress progress messages?}
}
\value{
Logical. TRUE if setup is complete, FALSE otherwise.
}
\description{
Verifies that all requirements for local LLM inference are met,
including Python environment, llama-cpp-python installation, and
model file accessibility.
}
